{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from collections import defaultdict\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceRecognition:\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.TRAIN_IMG_FOLDER = './images/TestDetected/'\n",
    "        self.train_imgs_names = os.listdir(self.TRAIN_IMG_FOLDER)\n",
    "        self.label_dict = defaultdict(int)\n",
    "        # amira 1/doha 2/maha 3/mariam 4/mayar 5\n",
    "        for name in self.train_imgs_names:\n",
    "            label = name.split('_')[0]\n",
    "            if label not in self.label_dict:\n",
    "                self.label_dict[label] = len(self.label_dict) + 1\n",
    "\n",
    "        self.width = 128\n",
    "        self.height = 128\n",
    "        self.mean_face = np.zeros((1,self.height * self.width))\n",
    "        self.Proj_Training_Matrix = None\n",
    "        self.eigenvalues = None\n",
    "        self.eigenvectors = None\n",
    "        self.weights = None\n",
    "        self.best_threshold = None\n",
    "\n",
    "\n",
    "    def pca(self):\n",
    "\n",
    "        Training_Matrix   = np.ndarray(shape=(len(self.train_imgs_names), self.height * self.width), dtype=np.float64)\n",
    "        for i in range(len( self.train_imgs_names)):\n",
    "\n",
    "            img = cv2.imread(self.TRAIN_IMG_FOLDER +  self.train_imgs_names[i], cv2.IMREAD_GRAYSCALE)\n",
    "            Training_Matrix[i,:] = np.array(img, dtype='float64').flatten()\n",
    "\n",
    "\n",
    "        for i in Training_Matrix:\n",
    "             self.mean_face = np.add(self.mean_face,i)\n",
    "        self.mean_face = np.divide(self.mean_face,float(Training_Matrix.shape[0])).flatten()\n",
    "\n",
    "        Normalised_Training_Matrix = np.ndarray(shape=(Training_Matrix.shape[0], Training_Matrix.shape[1]))\n",
    "        for i in range(len(self.train_imgs_names)):\n",
    "            Normalised_Training_Matrix[i] = np.subtract(Training_Matrix[i],self.mean_face)\n",
    "        cov_matrix=np.cov(Normalised_Training_Matrix)\n",
    "        cov_matrix = np.divide(cov_matrix,float(len(self.train_imgs_names)))  \n",
    "        self.eigenvalues, self.eigenvectors, = np.linalg.eig(cov_matrix)\n",
    "\n",
    "        sorted_ind = sorted(range(self.eigenvalues.shape[0]), key=lambda k: self.eigenvalues[k], reverse=True) \n",
    "        self.eigenvalues = self.eigenvalues[sorted_ind]\n",
    "        self.eigenvectors = self.eigenvectors[sorted_ind]  \n",
    "\n",
    "        # var_comp_sum = np.cumsum(self.eigenvalues)/sum(self.eigenvalues)\n",
    "        # for num_comp in range(1, len(self.eigenvalues) + 1):\n",
    "        #     if var_comp_sum[num_comp - 1] >= 0.9:\n",
    "        #         break\n",
    "\n",
    "        # reduced_eigvectors = np.array(self.eigenvectors[:num_comp]).transpose()\n",
    "        # self.Proj_Training_Matrix = np.dot(Training_Matrix.transpose(),reduced_eigvectors)\n",
    "\n",
    "        self.Proj_Training_Matrix = np.dot(Training_Matrix.transpose(),self.eigenvectors)\n",
    "        self.Proj_Training_Matrix =  self.Proj_Training_Matrix.transpose()\n",
    "\n",
    "        self.weights = np.array([np.dot( self.Proj_Training_Matrix,i) for i in Normalised_Training_Matrix])\n",
    "\n",
    "\n",
    "    def threshold_range(self):\n",
    "\n",
    "        euclidean_values = []\n",
    "        for img in self.test_imgs_names:\n",
    "\n",
    "            unknown_face = cv2.imread(self.TEST_IMG_FOLDER+img,0)        \n",
    "            unknown_face_vector = np.array(unknown_face, dtype='float64').flatten()\n",
    "            normalised_uface_vector = np.subtract(unknown_face_vector,self.mean_face)\n",
    "\n",
    "            unknown_weights = np.dot(self.Proj_Training_Matrix, normalised_uface_vector)\n",
    "            diff  = self.weights - unknown_weights\n",
    "            Euclidean_dist = np.linalg.norm(diff, axis=1)\n",
    "            index = np.argmin(Euclidean_dist)\n",
    "            euclidean_values.append( Euclidean_dist[index])\n",
    "        return( min(euclidean_values) , max(euclidean_values) )\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    def train(self):\n",
    "        # Load and preprocess the training images\n",
    "        X_train = []\n",
    "        y_train = []\n",
    "        for name in self.train_imgs_names:\n",
    "            img = cv2.imread(self.TRAIN_IMG_FOLDER + name, cv2.IMREAD_GRAYSCALE)\n",
    "            img = cv2.resize(img, (self.width, self.height))\n",
    "            X_train.append(img.flatten())\n",
    "            label = self.label_dict[name.split('_')[0]]\n",
    "            y_train.append(label)\n",
    "        print(y_train)\n",
    "        # Perform PCA on the training images\n",
    "        self.pca()\n",
    "\n",
    "        # Project the training images onto the PCA subspace\n",
    "        X_train_proj = np.dot(self.Proj_Training_Matrix, np.array(X_train).T).T\n",
    "\n",
    "        param_grid = {'kernel' : ('poly', 'rbf'), 'C':[0.01, 0.1, 0.5, 1, 10,50,100,1000],'gamma':[0.1,0.01,0.001,0.0001,0.00001,0.000001]}\n",
    "        gs = GridSearchCV(estimator=SVC(kernel='rbf'),\n",
    "        param_grid=param_grid,\n",
    "        refit=True, # choose best model and refit to entire data\n",
    "        n_jobs=None)\n",
    "        gs.fit(X_train_proj,y_train)\n",
    "\n",
    "        best_params = gs.best_params_\n",
    "        print('Best Params:', best_params)\n",
    "        bestModel = SVC(kernel=best_params['kernel'],C=best_params['C'])\n",
    "        bestModel.fit(X_train_proj,y_train)\n",
    "        print('Accuracy of SVC on training set: {:.2f}'.format(bestModel.score(Xtrain_pca,y_train)*100))\n",
    "        print('Accuracy of SVC on test set: {:.2f}'.format(bestModel.score(Xtest_pca,y_test)*100))\n",
    "\n",
    "\n",
    "        print(accuracy_score(y_test,y_pred))\n",
    "\n",
    "        # Train an SVM classifier on the projected training images\n",
    "        self.classifier = SVC(kernel='rbf', C=1, gamma='auto')\n",
    "        self.classifier.fit(X_train_proj, y_train)\n",
    "\n",
    "    def recognize(self, img_path):\n",
    "        # Load and preprocess the test image\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (self.width, self.height))\n",
    "        img_vec = np.array(img, dtype='float64').flatten()\n",
    "        img_vec_norm = np.subtract(img_vec, self.mean_face)\n",
    "\n",
    "        # Project the test image onto the PCA subspace\n",
    "        img_proj = np.dot(self.Proj_Training_Matrix, img_vec_norm)\n",
    "        # Predict the label of the test image using the k-NN classifier\n",
    "        label = self.classifier.predict([img_proj])[0]\n",
    "        # Return the name of the predicted person\n",
    "        for name, label_int in self.label_dict.items():\n",
    "            if label_int == label:\n",
    "                return name\n",
    "        return 'Unknown'\n",
    "    \n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'amira': 1,\n",
       "             'doha': 2,\n",
       "             'maha': 3,\n",
       "             'mariam': 4,\n",
       "             'mayar': 5,\n",
       "             'unknown': 6})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = FaceRecognition()\n",
    "f.train()\n",
    "f.label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amira_1.jpeg doha\n",
      "amira_11.jpeg doha\n",
      "amira_12.jpeg doha\n",
      "amira_2.jpeg doha\n",
      "amira_3.jpeg doha\n",
      "amira_4.jpeg doha\n",
      "amira_5.jpeg doha\n",
      "amira_6.jpeg doha\n",
      "amira_7.jpeg doha\n",
      "amira_8.jpeg doha\n",
      "amira_9.jpeg doha\n",
      "doha_1.jpeg doha\n",
      "doha_10.jpeg doha\n",
      "doha_11.jpeg doha\n",
      "doha_12.jpeg doha\n",
      "doha_13.jpeg doha\n",
      "doha_14.jpeg doha\n",
      "doha_2.jpeg doha\n",
      "doha_3.jpeg doha\n",
      "doha_4.jpeg doha\n",
      "doha_5.jpeg doha\n",
      "doha_6.jpeg doha\n",
      "doha_7.jpeg doha\n",
      "doha_8.jpeg doha\n",
      "doha_9.jpeg doha\n",
      "maha_1.jpeg doha\n",
      "maha_10.jpeg doha\n",
      "maha_11.jpeg doha\n",
      "maha_12.jpeg doha\n",
      "maha_2.jpeg doha\n",
      "maha_3.jpeg doha\n",
      "maha_4.jpeg doha\n",
      "maha_5.jpeg doha\n",
      "maha_6.jpeg doha\n",
      "maha_7.jpeg doha\n",
      "maha_8.jpeg doha\n",
      "maha_9.jpeg doha\n",
      "mariam_1.jpg doha\n",
      "mariam_10.jpg doha\n",
      "mariam_11.jpg doha\n",
      "mariam_2.jpg doha\n",
      "mariam_3.jpg doha\n",
      "mariam_4.jpg doha\n",
      "mariam_5.jpg doha\n",
      "mariam_6.jpg doha\n",
      "mariam_7.jpg doha\n",
      "mariam_8.jpg doha\n",
      "mariam_9.jpg doha\n",
      "mayar_10.jpeg doha\n",
      "mayar_11.jpeg doha\n",
      "mayar_12.jpeg doha\n",
      "mayar_2.jpeg doha\n",
      "mayar_3.jpeg doha\n",
      "mayar_4.jpeg doha\n",
      "mayar_5.jpeg doha\n",
      "mayar_6.jpeg doha\n",
      "mayar_7.jpeg doha\n",
      "mayar_8.jpeg doha\n",
      "mayar_9.jpeg doha\n",
      "unknown_1.jpeg doha\n",
      "unknown_2.jpeg doha\n",
      "unknown_3.jpeg doha\n",
      "unknown_4.jpeg doha\n",
      "unknown_5.jpeg doha\n",
      "unknown_6.jpeg doha\n"
     ]
    }
   ],
   "source": [
    "TEST_IMG_FOLDER = 'E:/THIRD YEAR/Second term/cv/tasks/task5/images/TestDetected/'\n",
    "test_image_names = os.listdir(TEST_IMG_FOLDER)\n",
    "for i in range(len(test_image_names)):\n",
    "   print(test_image_names[i] ,f.recognize(TEST_IMG_FOLDER + test_image_names[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
