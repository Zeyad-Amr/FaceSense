{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'your_image.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mPIL\u001b[39;00m \u001b[39mimport\u001b[39;00m Image\n\u001b[0;32m      4\u001b[0m \u001b[39m# Load the image\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39;49mopen(\u001b[39m\"\u001b[39;49m\u001b[39myour_image.jpg\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      7\u001b[0m \u001b[39m# Convert the image to a numpy array\u001b[39;00m\n\u001b[0;32m      8\u001b[0m img_array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(img)\n",
      "File \u001b[1;32mc:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\PIL\\Image.py:3227\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3224\u001b[0m     filename \u001b[39m=\u001b[39m fp\n\u001b[0;32m   3226\u001b[0m \u001b[39mif\u001b[39;00m filename:\n\u001b[1;32m-> 3227\u001b[0m     fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39;49mopen(filename, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m   3228\u001b[0m     exclusive_fp \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   3230\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'your_image.jpg'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Load the image\n",
    "img = Image.open(\"your_image.jpg\")\n",
    "\n",
    "# Convert the image to a numpy array\n",
    "img_array = np.array(img)\n",
    "\n",
    "# Flatten the array to a 1D array\n",
    "img_1d = img_array.flatten()\n",
    "\n",
    "# Print the shape of the 1D array\n",
    "print(img_1d.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'archive/lfw-funneled.tgz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m class_name\u001b[39m=\u001b[39m[]\n\u001b[0;32m     22\u001b[0m path\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39marchive/lfw-funneled.tgz\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 23\u001b[0m tar \u001b[39m=\u001b[39m tarfile\u001b[39m.\u001b[39;49mopen(path, \u001b[39m\"\u001b[39;49m\u001b[39mr:gz\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     24\u001b[0m counter\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[0;32m     25\u001b[0m \u001b[39mfor\u001b[39;00m tarinfo \u001b[39min\u001b[39;00m tar:\n",
      "File \u001b[1;32mc:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python38\\lib\\tarfile.py:1617\u001b[0m, in \u001b[0;36mTarFile.open\u001b[1;34m(cls, name, mode, fileobj, bufsize, **kwargs)\u001b[0m\n\u001b[0;32m   1615\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1616\u001b[0m         \u001b[39mraise\u001b[39;00m CompressionError(\u001b[39m\"\u001b[39m\u001b[39munknown compression type \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m comptype)\n\u001b[1;32m-> 1617\u001b[0m     \u001b[39mreturn\u001b[39;00m func(name, filemode, fileobj, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1619\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m|\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1620\u001b[0m     filemode, comptype \u001b[39m=\u001b[39m mode\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m|\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python38\\lib\\tarfile.py:1664\u001b[0m, in \u001b[0;36mTarFile.gzopen\u001b[1;34m(cls, name, mode, fileobj, compresslevel, **kwargs)\u001b[0m\n\u001b[0;32m   1661\u001b[0m     \u001b[39mraise\u001b[39;00m CompressionError(\u001b[39m\"\u001b[39m\u001b[39mgzip module is not available\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1663\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1664\u001b[0m     fileobj \u001b[39m=\u001b[39m gzip\u001b[39m.\u001b[39;49mGzipFile(name, mode \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mb\u001b[39;49m\u001b[39m\"\u001b[39;49m, compresslevel, fileobj)\n\u001b[0;32m   1665\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[0;32m   1666\u001b[0m     \u001b[39mif\u001b[39;00m fileobj \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python38\\lib\\gzip.py:173\u001b[0m, in \u001b[0;36mGzipFile.__init__\u001b[1;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[0;32m    171\u001b[0m     mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    172\u001b[0m \u001b[39mif\u001b[39;00m fileobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 173\u001b[0m     fileobj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmyfileobj \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39;49mopen(filename, mode \u001b[39mor\u001b[39;49;00m \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m    174\u001b[0m \u001b[39mif\u001b[39;00m filename \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    175\u001b[0m     filename \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(fileobj, \u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'archive/lfw-funneled.tgz'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "# import keras\n",
    "# import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# from keras.preprocessing import image\n",
    "from matplotlib import pyplot as plt\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, Input, Dropout, Flatten, Layer, Conv2D, Lambda, MaxPooling2D\n",
    "# from keras import regularizers\n",
    "# from keras.losses import categorical_crossentropy\n",
    "# import keras.utils\n",
    "# from keras import backend as K\n",
    "import tarfile\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "class_name=[]\n",
    "path=\"archive/lfw-funneled.tgz\"\n",
    "tar = tarfile.open(path, \"r:gz\")\n",
    "counter=0\n",
    "for tarinfo in tar:\n",
    "    tar.extract(tarinfo.name)\n",
    "    if tarinfo.name[-4:]==\".jpg\":\n",
    "        people_name=os.path.basename(tarinfo.name).split('.')[0].rsplit('_', 1)[0]\n",
    "        image = cv2.imread(tarinfo.name)\n",
    "        X.append(np.array(image))\n",
    "        Y.append(people_name)\n",
    "    if tarinfo.isdir():\n",
    "        class_name.append(os.path.basename(tarinfo.name))\n",
    "        pass\n",
    "tar.close()\n",
    "class_name=class_name[1:]\n",
    "X= np.array(X)\n",
    "print(\"LFW images have been fetched\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(187500,)\n",
      "(13233, 187500)\n",
      "['George_HW_Bush' 'George_HW_Bush' 'George_HW_Bush' ... 'Leticia_Dolera'\n",
      " 'Joseph_Fiennes' 'Colin_Prescot']\n"
     ]
    }
   ],
   "source": [
    "print(X[0].flatten().shape)\n",
    "X = X.reshape(X.shape[0],-1)\n",
    "# for i in range(len(X)):\n",
    "#     X[i].reshape(X[i].flatten().shape[0])\n",
    "#     X[i] = X[i].flatten()\n",
    "    \n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convert_classes_to_numbers(arr):\n",
    "    unique_values = np.unique(arr)\n",
    "    class_to_num = {class_name: i for i, class_name in enumerate(unique_values)}\n",
    "    return np.vectorize(class_to_num.get)(arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5749,)\n"
     ]
    }
   ],
   "source": [
    "y = np.array(Y)\n",
    "y = convert_classes_to_numbers(y)\n",
    "print(np.unique(y).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 4096)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 39\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[39mprint\u001b[39m (np\u001b[39m.\u001b[39marray(pixels)\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     37\u001b[0m \u001b[39m# show_orignal_images(pixels)\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[39m## Step 2: Split Dataset into training and testing\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m x_train, x_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X, y)\n\u001b[0;32m     41\u001b[0m \u001b[39m## Step 3: Perform PCA.\u001b[39;00m\n\u001b[0;32m     42\u001b[0m pca \u001b[39m=\u001b[39m PCA(n_components\u001b[39m=\u001b[39m\u001b[39m150\u001b[39m)\u001b[39m.\u001b[39mfit(x_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "##Helper functions. Use when needed. \n",
    "def show_orignal_images(pixels):\n",
    "\t#Displaying Orignal Images\n",
    "    fig, axes = plt.subplots(6, 10, figsize=(11, 7),subplot_kw={'xticks':[], 'yticks':[]})\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(np.array(pixels)[i].reshape(64, 64), cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "def show_eigenfaces(pca):\n",
    "\t#Displaying Eigenfaces\n",
    "    fig, axes = plt.subplots(3, 8, figsize=(9, 4),subplot_kw={'xticks':[], 'yticks':[]})\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(pca.components_[i].reshape(64, 64), cmap='gray')\n",
    "        ax.set_title(\"PC \" + str(i+1))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "## Step 1: Read dataset and visualize it\n",
    "df = pd.read_csv(\"face_data.csv\")\n",
    "targets = df[\"target\"]\n",
    "pixels = df.drop([\"target\"],axis=1)\n",
    "\n",
    "print (np.array(pixels).shape)\n",
    "\n",
    "# show_orignal_images(pixels)\n",
    "## Step 2: Split Dataset into training and testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "## Step 3: Perform PCA.\n",
    "pca = PCA(n_components=150).fit(x_train)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance');\n",
    "plt.show()\n",
    "\n",
    "# show_eigenfaces(pca)\n",
    "\n",
    "## Step 4: Project Training data to PCA\n",
    "print(\"Projecting the input data on the eigenfaces orthonormal basis\")\n",
    "Xtrain_pca = pca.transform(x_train)\n",
    "\n",
    "##############\n",
    "\n",
    "## Step 5: Initialize Classifer and fit training data\n",
    "clf = SVC(kernel='rbf',C=1000,gamma=0.001)\n",
    "clf = clf.fit(Xtrain_pca, y_train)\n",
    "\n",
    "param_grid = {'kernel' : ('poly', 'rbf'), 'C':[0.01, 0.1, 0.5, 1, 10,50,100,1000],'gamma':[0.1,0.01,0.001,0.0001,0.00001,0.000001]}\n",
    "gs = GridSearchCV(estimator=SVC(kernel='rbf'),\n",
    "param_grid=param_grid,\n",
    "refit=True, # choose best model and refit to entire data\n",
    "cv=10,\n",
    "n_jobs=None)\n",
    "gs.fit(Xtrain_pca,y_train)\n",
    "\n",
    "best_params = gs.best_params_\n",
    "print('Best Params:', best_params)\n",
    "bestModel = SVC(kernel=best_params['kernel'],C=best_params['C'])\n",
    "bestModel.fit(Xtrain_pca,y_train)\n",
    "print('Accuracy of SVC on training set: {:.2f}'.format(bestModel.score(Xtrain_pca,y_train)*100))\n",
    "print('Accuracy of SVC on test set: {:.2f}'.format(bestModel.score(x_test,y_test)*100))\n",
    "\n",
    "\n",
    "## Step 6: Perform testing and get classification report\n",
    "# print(\"Predicting people's names on the test set\")\n",
    "# t0 = time()\n",
    "# Xtest_pca = pca.transform(x_test)\n",
    "# y_pred = clf.predict(Xtest_pca)\n",
    "# print(\"done in %0.3fs\" % (time() - t0))\n",
    "# print(classification_report(y_test, y_pred))\n",
    "# print(accuracy_score(y_test,y_pred))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
